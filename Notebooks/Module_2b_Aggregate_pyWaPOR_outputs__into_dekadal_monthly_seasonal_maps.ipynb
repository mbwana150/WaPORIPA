{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDDyUu-vXc-Y"
      },
      "source": [
        "!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bdXzjxqXrZx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade xarray --quiet\n",
        "!pip install --upgrade rioxarray --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOJ77jsKXWuM"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import rioxarray as rio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_fw8CSak9Z",
        "outputId": "05cbed93-0685-41fb-95fc-5e3225e13837"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "%cd /content/gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9En9y1jrXWuN"
      },
      "outputs": [],
      "source": [
        "# functions to calculate dekadal, monthly and seasonal sums from the ET_look output netcdf file\n",
        "def resotor_encoding(ds, encoding, var_attrs, temp_res):\n",
        "    # Restore encoding information\n",
        "    for var in ds.data_vars:\n",
        "        if var in encoding:  # Ensure the variable exists in the original encoding\n",
        "            ds[var].encoding = encoding[var]\n",
        "\n",
        "    for var in ds.data_vars:\n",
        "        if var in var_attrs:  # Ensure the variable exists in the original encoding\n",
        "            attrs = ds[var].attrs\n",
        "            attrs_to_delete = [j for j in attrs if 'NETCDF_' in j or 'scale_factor' in j]\n",
        "            attrs = {key: attrs[key] for key in attrs if key not in attrs_to_delete}\n",
        "            lname = attrs['long_name']\n",
        "            lname = lname.replace(\"Daily\", temp_res)\n",
        "            attrs.update({'long_name': lname, \n",
        "                          'source_data': 'Aggregated from ET_Look model output',\n",
        "                          'units' : f\"mm/{temp_res[:-2]}\",\n",
        "                          'temporal_resolution' : temp_res,})\n",
        "            ds[var].attrs = attrs\n",
        "    return ds\n",
        "\n",
        "# decadal sum\n",
        "def dekadal_sum(ds):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "    attrs = {var: ds[var].attrs for var in ds.data_vars}\n",
        "    # aggegate to dekadal values (10,10, and 10/11/9/8 based on the eyar and the month)\n",
        "    d = ds.time.dt.day - np.clip((ds.time.dt.day-1) // 10, 0, 2)*10 - 1\n",
        "    date = ds.time.values - np.array(d, dtype=\"timedelta64[D]\")\n",
        "    ds['time'] = date\n",
        "    ds_dk = ds.groupby(ds.time).sum(dim='time', skipna=False, keep_attrs=True)\n",
        "    # Restore encoding information\n",
        "    ds_dk = resotor_encoding(ds_dk, encoding, attrs, 'Dekadal') #resotor_encoding(ds_dk, encoding, attrs, 'dekadal')\n",
        "    return ds_dk\n",
        "\n",
        "# Monthly sum\n",
        "def monthly_sum(ds):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "    attrs = {var: ds[var].attrs for var in ds.data_vars}\n",
        "    # aggregate to monthly\n",
        "    ds_mn = ds.resample(time=\"1ME\").sum(skipna=False)\n",
        "    # Restore encoding information\n",
        "    ds_mn = resotor_encoding(ds_mn, encoding, attrs, 'Monthly')\n",
        "    return ds_mn\n",
        "# Check if the start and end time of the selected dataarray corresponds to sos and eos\n",
        "def select_season_da(da_var, season_start_date, season_end_date):\n",
        "\n",
        "    sos = datetime.datetime.fromisoformat(season_start_date) #start of season date, we use datetime.datetime to convert the year, month, day to a datetime object\n",
        "    eos = datetime.datetime.fromisoformat(season_end_date) #end of season date\n",
        "\n",
        "    da_st = datetime.datetime.fromisoformat(pd.to_datetime(da_var.time.data).strftime('%Y-%m-%d')[0])\n",
        "    da_et = datetime.datetime.fromisoformat(pd.to_datetime(da_var.time.data).strftime('%Y-%m-%d')[-1])\n",
        "    try:\n",
        "        if (sos >= da_st) or (eos <= da_et):\n",
        "            da = da_var.sel(time=slice(sos, eos))\n",
        "            return da\n",
        "        else:\n",
        "            print(\"The sos and/or eos out of the time range of the dataset.\")\n",
        "            da = da_var.sel(time=slice(sos, eos))\n",
        "            return da\n",
        "    except ValueError:\n",
        "        print(\"Erro in selecting data for the season.\")\n",
        "\n",
        "# Seasonal Resample\n",
        "def seasonal_sum(ds, sos, eos):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "    attrs = {var: ds[var].attrs for var in ds.data_vars}\n",
        "\n",
        "    ds_sn = select_season_da(ds, sos, eos).sum(dim = 'time', skipna=False)\n",
        "    # Restore encoding information\n",
        "    ds_sn = resotor_encoding(ds_sn, encoding, attrs, 'Seasonal')\n",
        "    for var in ds_sn.data_vars:\n",
        "        if var in encoding:  # Ensure the variable exists in the original encoding\n",
        "            encoding[var]['sos']= sos\n",
        "            encoding[var]['eos']= eos\n",
        "            ds_sn[var].encoding = encoding[var]\n",
        "    return ds_sn\n",
        "  \n",
        "def reproject(ds, to_crs):\n",
        "#   encoding = ds.econding #{var: ds[var].encoding for var in ds.data_vars}\n",
        "  try:\n",
        "      if 'EPSG'.lower() in str(to_crs).lower():\n",
        "        #   print(to_crs)\n",
        "          dst = ds.rio.reproject(to_crs)\n",
        "          return dst\n",
        "      else: # assume it is a path to template file\n",
        "        if os.path.exists(to_crs):\n",
        "            # print(\"Use a template raster to repoject the dataset\")\n",
        "            temp_rst_file = to_crs\n",
        "            da_rst = rio.open_rasterio(temp_rst_file)\n",
        "            if da_rst.rio.crs != None:\n",
        "                dst= ds.rio.reproject_match(da_rst)\n",
        "                return dst\n",
        "            else:\n",
        "                print(f\"the template raster {temp_rst_file} does not have CRS information.\")\n",
        "  except ValueError:\n",
        "        print(\"Your input is not either a valid EPSG code or a teplate raster path.\")\n",
        "\n",
        "switcher = {\n",
        "        'et': 'AETI',\n",
        "        'e': 'E',\n",
        "        'int': 'I',\n",
        "        'npp': 'NPP',\n",
        "        't': 'T',\n",
        "        'se': 'RSM',\n",
        "        'dekadal': 'D',\n",
        "        'monthly': 'M',\n",
        "        'seasonal': 'S'\n",
        "    }\n",
        "def get_code(code_name):\n",
        "    func = switcher.get(code_name, \"nothing\")\n",
        "    # Execute the function\n",
        "    return func\n",
        "\n",
        "# write to file\n",
        "def write_file(da, to_crs, fname, encoding, date, attrs, temporal_res) :\n",
        "    if(to_crs!=None):\n",
        "        # reproject the data. provide a crs in the form of f\"EPSG:{epsg code}\" or a path to template raster\n",
        "        da = reproject(da, to_crs)\n",
        "    # Modify the attributes\n",
        "    attrs.update({'date': date})\n",
        "    da.attrs  = attrs\n",
        "    da = da.round(2)\n",
        "    da.encoding = encoding   #['scale_factor'] = 1.0\n",
        "    da.rio.to_raster(f\"{fname}.tif\", driver=\"GTiff\", compress=\"LZW\")\n",
        "    da.close()\n",
        "\n",
        "# netCDF to geotiff\n",
        "def write2gtiff(ds, temporal_res, dir_out, to_crs = None):\n",
        "  \n",
        "  if 'time' in ds.dims:\n",
        "      date_str = pd.to_datetime(ds.time.data).strftime('%Y-%m-%d')\n",
        "\n",
        "  for var in ds.data_vars:\n",
        "    var_name = get_code(var.split('_')[0])\n",
        "    time_code = get_code(temporal_res)\n",
        "    var_name = f\"{var_name}_{time_code}\"\n",
        "    fd = os.path.join(dir_out, temporal_res, f\"pywapor_{var_name}\")\n",
        "    encoding  = ds[var].encoding\n",
        "    encoding['dtype'] = 'float32'\n",
        "    encoding['scale_factor'] = 1.0\n",
        "    encoding['_FillValue'] = encoding['_FillValue'].astype('float32')\n",
        "    # print(encoding)\n",
        "    attrs = ds[var].attrs\n",
        "    if(temporal_res.lower() == 'seasonal'):\n",
        "        sos = encoding['sos']\n",
        "        eos = encoding['eos']\n",
        "    # Create folder per variable.\n",
        "    if not os.path.isdir(fd):\n",
        "        os.makedirs(fd)\n",
        "\n",
        "    if(temporal_res.lower() != 'seasonal'):\n",
        "        for i in range(len(ds.time)):\n",
        "            date = date_str[i]\n",
        "            fname = os.path.join(fd, f\"pywapor_{var_name}_{date}\")\n",
        "            da = ds[var][i]\n",
        "            da = da.drop_vars('time')  # get the data for one time step\n",
        "            write_file(da, to_crs, fname, encoding, date, attrs, temporal_res)    \n",
        "    else:\n",
        "        date = f\"{sos}_{eos}\"\n",
        "        fname = os.path.join(fd, f\"pywapor_{var_name}_{date}\")\n",
        "        da = ds[var]\n",
        "        write_file(da, to_crs, fname, encoding, date, attrs, temporal_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpPAxwywXWuP"
      },
      "source": [
        "#### Step 1: Read pywapor output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74LRxs82XWuR"
      },
      "outputs": [],
      "source": [
        "# path to the et_look_out/nc file\n",
        "path_et_look_out = r'/content/gdrive/MyDrive/pywapor/et_look_out.nc'\n",
        "xr.set_options(keep_attrs=True)\n",
        "ds = xr.open_dataset(path_et_look_out, decode_coords=\"all\")\n",
        "ds = ds.rename({'time_bins': 'time'})\n",
        "# ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMRsw0uRXWuS"
      },
      "source": [
        "#### Step 2: Aggregate to the required timestep (dekadal, monthly or seasonal) and write the result to individual geotiff files per time step\n",
        "The ET_look output is in EPSG:4326, if you would like to reproject the dataset to other projections such UTM zone, provide the required epsg code or a path to raster template file. The defualt is an estimated utm crs from the dataset. if you want to change provide the crs in the following style: to_crs = f\"EPSG:{epsg code (number)}\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ybtj53qti1X"
      },
      "outputs": [],
      "source": [
        "dir_out = r'/content/gdrive/MyDrive/pywapor' # a folder in your gdrive to save the geotif files\n",
        "# dir_out = r'pywapor_out' # a folder in colab working directory to save the geotif files\n",
        "\n",
        "# estinated utm crs from the dataset\n",
        "to_crs = ds.rio.estimate_utm_crs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJN1W2BjXWuT"
      },
      "outputs": [],
      "source": [
        "# aggregate to dekadal timestep\n",
        "ds_dk = dekadal_sum(ds) # dekadal\n",
        "temporal_res = 'dekadal'\n",
        "write2gtiff(ds_dk, temporal_res, dir_out, to_crs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDmZqPbxTh17"
      },
      "outputs": [],
      "source": [
        "# aggregate to monthly timestep\n",
        "ds_mn = monthly_sum(ds) # monthly\n",
        "temporal_res = 'monthly'\n",
        "write2gtiff(ds_mn, temporal_res, dir_out, to_crs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs5Hnpv7TipI"
      },
      "outputs": [],
      "source": [
        "# aggregate to a season\n",
        "season_start_date = '2022-10-01' # start od the season in iso format\n",
        "season_end_date = '2023-04-30' # end of the season in iso format\n",
        "ds_sn = seasonal_sum(ds, season_start_date, season_end_date)\n",
        "temporal_res = 'seasonal'\n",
        "write2gtiff(ds_sn, temporal_res, dir_out, to_crs )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0U4nygsuuo"
      },
      "source": [
        "\n",
        "### Zip and downalod the data folder to your local drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jC5PwcYNsu-m",
        "outputId": "a42e6bc4-0f1a-426a-919b-8be414b41e70"
      },
      "outputs": [],
      "source": [
        "\n",
        "!zip -r /content/pywapor.zip /content/gdrive/MyDrive/pywapor_out\n",
        "from google.colab import files\n",
        "files.download('/content/pywapor.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pywapor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
