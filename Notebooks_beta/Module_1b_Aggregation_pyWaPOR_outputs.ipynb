{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Module 1b: Aggregating pyWaPOR outputs into dekadal/ monthly and seasonal maps\n",
        "\n",
        "In this Notebook we use a script that was developed for the WaPOR project to calculate temporal aggregation of pyWaPOR output (AETI, T and NPP), which are needed to run the irrigation performance assessment module.\n",
        "This script exports the WaPOR netCDF file into dekadal/ monthly and seasonal TIFF maps.\n",
        "\n",
        "This script follows the following steps:\n",
        "\n",
        "*  Step 0: Import modules/libraries\n",
        "*  Step 1: Define functions for aggregating pyWaPOR outputs\n",
        "*  Step 2: Read pywapor output and reproject the xarray\n",
        "*  Step 3: Aggregate to the required timestep\n",
        "*  Step 4: Write the result\n",
        "\n"
      ],
      "metadata": {
        "id": "SDDyUu-vXc-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0. Import modules/libraries"
      ],
      "metadata": {
        "id": "LnBJNMZ2M6Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade xarray --quiet\n",
        "!pip install --upgrade rioxarray --quiet\n"
      ],
      "metadata": {
        "id": "9bdXzjxqXrZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOJ77jsKXWuM"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import rioxarray as rio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Define function to aggregate pyWaPOR output data"
      ],
      "metadata": {
        "id": "EQs6DuCIO6bQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9En9y1jrXWuN"
      },
      "outputs": [],
      "source": [
        "# functions to calculate dekadal, monthly and seasonal sums from the ET_look output netcdf file\n",
        "\n",
        "# decadal sum\n",
        "def dekadal_sum(ds):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "\n",
        "    d = ds.time.dt.day - np.clip((ds.time.dt.day-1) // 10, 0, 2)*10 - 1\n",
        "    date = ds.time.values - np.array(d, dtype=\"timedelta64[D]\")\n",
        "    ds['time'] = date\n",
        "    ds_dk = ds.groupby(ds.time).sum(dim='time', keep_attrs=True)\n",
        "    # Restore encoding information\n",
        "    for var in ds_dk.data_vars:\n",
        "        if var in encoding:  # Ensure the variable exists in the original encoding\n",
        "            ds_dk[var].encoding = encoding[var]\n",
        "\n",
        "    return ds_dk\n",
        "\n",
        "# Monthly sum\n",
        "def monthly_sum(ds):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "\n",
        "    ds_mn = ds.resample(time=\"1ME\").sum()\n",
        "    # Restore encoding information\n",
        "    for var in ds_mn.data_vars:\n",
        "        if var in encoding:  # Ensure the variable exists in the original encoding\n",
        "            ds_mn[var].encoding = encoding[var]\n",
        "    return ds_mn\n",
        "# Check if the start and end time of the selected dataarray corresponds to sos and eos, if not adjust the data array based on the times\n",
        "def select_season_da(da_var, season_start_date, season_end_date):\n",
        "\n",
        "    sos = datetime.datetime.fromisoformat(season_start_date) #start of season date, we use datetime.datetime to convert the year, month, day to a datetime object\n",
        "    eos = datetime.datetime.fromisoformat(season_end_date) #end of season date\n",
        "    da = da_var.sel(time=slice(sos, eos))\n",
        "    st_da = da.time[0]\n",
        "    et_da = da.time[-1]\n",
        "\n",
        "    st_dif = pd.to_datetime(st_da.data) - sos\n",
        "    en_dif = eos - pd.to_datetime(et_da.data)\n",
        "\n",
        "    idx1 = list(da_var.time.values).index(da_var.sel(time=da.time[0], method='nearest').time)\n",
        "    idx2 = list(da_var.time.values).index(da_var.sel(time=da.time[-1], method='nearest').time)\n",
        "\n",
        "    d1 = st_dif.days\n",
        "    d2 = (pd.to_datetime(da.time[0].data)-pd.to_datetime(da_var.time[idx1-1].data)).days\n",
        "\n",
        "    da_fr1 = da_var.sel(time=da_var.time[idx1-1])*d1/d2\n",
        "    da_fr1['time'] = sos\n",
        "\n",
        "    d3 = en_dif.days\n",
        "    d4 = (pd.to_datetime(da_var.time[idx2+1].data) - pd.to_datetime(da.time[-1].data)).days\n",
        "\n",
        "    da_fr2 = da_var.sel(time=da_var.time[idx1+1])*d3/d4\n",
        "    da_fr2['time'] = eos\n",
        "\n",
        "    if da_fr1.time.size != 0:\n",
        "        da = xr.concat([da_fr1, da], dim = 'time')\n",
        "\n",
        "    if da_fr2.time.size != 0:\n",
        "        da = xr.concat([da, da_fr2], dim = 'time')\n",
        "\n",
        "    return da\n",
        "\n",
        "# Seasonal Resample\n",
        "def seasonal_sum(ds, sos, eos):\n",
        "    # Store encoding information\n",
        "    encoding = {var: ds[var].encoding for var in ds.data_vars}\n",
        "\n",
        "    ds_sn = select_season_da(ds, sos, eos)\n",
        "    ds_sn = ds_sn.sum(dim = 'time')\n",
        "    # Restore encoding information\n",
        "    for var in ds_sn.data_vars:\n",
        "        if var in encoding:  # Ensure the variable exists in the original encoding\n",
        "            ds_sn[var].encoding = encoding[var]\n",
        "    return ds_sn\n",
        "\n",
        "# reproject the dataset\n",
        "def reproject(ds):\n",
        "  crs_info = input(f\"The estimated UTM crs is {ds.rio.estimate_utm_crs()}.\\nWould like to repoject the dataset? Enter a valid EPSG code\\\n",
        "  or a template raster file path: \")\n",
        "  try:\n",
        "      # Convert it into integer\n",
        "      to_crs = int(crs_info)\n",
        "      print(f\"project to EPSG:{crs_info}\")\n",
        "      to_crs = f\"EPSG:{to_crs}\"\n",
        "      dst = ds.rio.reproject(to_crs, resampling=Resampling.nearest, nodata=-9999)\n",
        "      return dst\n",
        "  except ValueError:\n",
        "      try:\n",
        "          if os.path.exists(crs_info):\n",
        "              print(\"Use a template raster to repoject the dataset\")\n",
        "              temp_rst_file = crs_info\n",
        "              da_rst = rio.open_rasterio(temp_rst_file)\n",
        "              if da_rst.rio.crs != None:\n",
        "                  dst= ds.rio.reproject_match(da_rst, nodata=-9999)\n",
        "                  return dst\n",
        "              else:\n",
        "                  print(f\"the template raster {temp_rst_file} does not have CRS information.\")\n",
        "      except ValueError:\n",
        "          print(\"Your input is not either a valid EPSG code or a teplate raster path.\")\n",
        "\n",
        "# netCDF to geotiff\n",
        "def write2gtiff(ds, temporal_res, dir_out):\n",
        "\n",
        "  date_str = pd.to_datetime(ds.time.data).strftime('%Y-%m-%d')\n",
        "  # Create folder per variable.\n",
        "  dir_out = r'/content/'+dir_out\n",
        "  if not os.path.isdir(dir_out):\n",
        "      os.makedirs(dir_out)\n",
        "\n",
        "  for var in ds.data_vars:\n",
        "    var_name = var.split('_')[0]\n",
        "    fd = os.path.join(dir_out, temporal_res, var_name)\n",
        "\n",
        "    encoding  = ds[var].encoding\n",
        "    attrs = ds[var].attrs\n",
        "    # Create folder per variable.\n",
        "    if not os.path.isdir(fd):\n",
        "        os.makedirs(fd)\n",
        "\n",
        "    for i in range(len(ds.time)):\n",
        "      fname = os.path.join(fd, f\"{var_name}_{date_str[i]}\")\n",
        "      da = ds[var][i]\n",
        "      da = da.drop_vars('time')  # get the data for one time step\n",
        "      da = da.where(da==encoding['_FillValue'], da*encoding['scale_factor'])\n",
        "\n",
        "      # Modify the attributes\n",
        "\n",
        "      attrs.update({'date': date_str[i],\n",
        "                    'units' : f\"mm/{temporal_res}\",\n",
        "                    'temporal_resolution' : temporal_res,\n",
        "                    'scale_factor' :1})\n",
        "      attrs_to_delete = [i for i in attrs if 'NETCDF_' in i]\n",
        "      attrs_new = {key: attrs[key] for key in attrs if key not in attrs_to_delete}\n",
        "      da.attrs  = attrs_new\n",
        "      # print(i, attrs_new)\n",
        "      # write the dataarray to a geotif file\n",
        "      da.rio.to_raster(f\"{fname}.tif\", driver=\"GTiff\", compress=\"LZW\")\n",
        "      da.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpPAxwywXWuP"
      },
      "source": [
        "## Step 2: Read pywapor output and reproject the xarray\n",
        "\n",
        "Set the path to the ET Look output file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74LRxs82XWuR"
      },
      "outputs": [],
      "source": [
        "# path to the et_look_out/nc file\n",
        "path_et_look_out = r'/content/et_look_out.nc'\n",
        "ds = xr.open_dataset(path_et_look_out, decode_coords=\"all\")\n",
        "ds = ds.rename({'time_bins': 'time'})\n",
        "# ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMRsw0uRXWuS"
      },
      "source": [
        " Reproject the xarray dataset if needed\n",
        "The ET Look output is in EPSG:4326, use the next cell to reproject the dataset to other projections, otherwise skip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f7pm9f_XWuT"
      },
      "outputs": [],
      "source": [
        "dst = reproject(ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIVRmFJXWuT"
      },
      "source": [
        "## Step 3: Aggregate to the required timestep (dekadal, monthly or seasonal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJN1W2BjXWuT"
      },
      "outputs": [],
      "source": [
        "# aggregate to the required timestep\n",
        "ds_mn = monthly_sum(dst) # monthly\n",
        "ds_dk = dekadal_sum(dst) # dekadal\n",
        "\n",
        "# for seasonal aggregation use the lines below:\n",
        "# aggregate to seasonal timestep (if applicable)\n",
        "# season_start_date = '2022-10-05' # start of the season in iso format\n",
        "# season_end_date = '2023-02-28' # end of the season in iso format\n",
        "# ds_sn = seasonal_sum(ds, season_start_date, season_end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i99lqGsrXWuU"
      },
      "source": [
        "## Step 4: Write the result to individual TIFF files per time step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM9RFWtCXWuU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create directory to store the tiff files\n",
        "dir_out = r'output' # folder to save the dekadal geotif files\n",
        "temporal_res = 'dekadal'\n",
        "write2gtiff(ds_dk, temporal_res, dir_out)\n",
        "\n",
        "#dir_out = r'output' # folder to save the monthly geotif files\n",
        "#temporal_res = 'monthly'\n",
        "#write2gtiff(ds_mn, temporal_res, dir_out)\n",
        "\n",
        "#dir_out = r'output' # folder to save the seasonal geotif files\n",
        "#temporal_res = 'seasonal'\n",
        "#write2gtiff(ds_sn, temporal_res, dir_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBimzqekXWuU"
      },
      "outputs": [],
      "source": [
        "# # test opening one of the geotiff files\n",
        "# rst_path = r'/content/output/dekadal/e/e_2022-10-01.tif'\n",
        "# da = rio.open_rasterio(rst_path)\n",
        "# da.plot()\n",
        "# da.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/pywapor_out.zip /content/output\n",
        "from google.colab import files\n",
        "files.download(r'/content/pywapor_out.zip')"
      ],
      "metadata": {
        "id": "_a2KLUFxiZNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pywapor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}