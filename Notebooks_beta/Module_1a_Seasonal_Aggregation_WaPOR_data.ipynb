{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_pk4_qHJekP"
      },
      "source": [
        "#Module 1a: Seasonal aggregation of WaPOR data\n",
        "\n",
        "In this Notebook we use a script that was developed for the WaPOR project to calculate temporal aggregation of WaPOR data (AETI, T and NPP), which are needed to run the irrigation performance assessment module.\n",
        "\n",
        "We will be following these steps:\n",
        "\n",
        "0. Import Python Libraries\n",
        "1. Import WaPOR data\n",
        "2. Define function for temporal aggregation\n",
        "3. Calculate seasonal AETI, T and NPP\n",
        "4. Calculate TBP from NPP\n",
        "\n",
        "**Data used:**\n",
        "\n",
        "For running this Notebook we used the following data which we downloaded using the [Download_WaPORv3_Data Notebook](https://github.com/wateraccounting/WaPORMOOC/blob/main/1_WaPOR_download_colab/Download_WaPORv3_Data.ipynb).\n",
        "\n",
        "1. **Area**: Wad Helal in the Gezira Irrigation Scheme (you can find the \\\"Wad_Helal.geojson\\\" file in the data folder of [WaPORMOOC](https://github.com/wateraccounting/WaPORMOOC/tree/main/data))\n",
        "2. **Type of Data**: AETI, T and NPP\n",
        "3. **Spatial resolution**: Level 3\n",
        "4. **Temporal resolution**: dekadal\n",
        "5. **Start date**: 2022-10-01\n",
        "6. **End date**: 2023-04-30\n",
        "\n",
        "The function `SumSeason` used in this Notebook is based on [WaPORWP](https://github.com/wateraccounting/WAPORWP)\n",
        "© 2020 Abebe Chukalla. Licensed under CC BY 4.0 Creative Commons.\n",
        "\n",
        " © 2024 IHE Delft Licenced under CC BY SA Creative Commons\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1TM45_yS6jz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOHkmq6KzN90"
      },
      "source": [
        "## Step 0. Import modules/libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFai3WdwQ7i3"
      },
      "outputs": [],
      "source": [
        "!pip install rioxarray --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dl6xEg_MzN90"
      },
      "outputs": [],
      "source": [
        "import os                                 # a module for interacting with the operating system\n",
        "import sys\n",
        "import glob                               # used to retrieve files/pathnames matching a specified pattern\n",
        "import re                                 # re sub() module can be used to replace substring\n",
        "import rioxarray as rio\n",
        "import pandas as pd                       # to store and manipulate tabular data in rows of observations and columns of variables\n",
        "import numpy as np                        # stands for 'Numerical Python, is a python library used for scientific computing with arrays\n",
        "import calendar\n",
        "import datetime\n",
        "from matplotlib import pyplot as plt      # is a plotting library used for 2D graphics in python\n",
        "from osgeo import gdal"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcGUHHSvHWXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylRqSb49kIhG"
      },
      "source": [
        "Upload the data downloaded using [Download_WaPORv3_Data Notebook](https://github.com/wateraccounting/WaPORMOOC/blob/main/1_WaPOR_download_colab/Download_WaPORv3_Data.ipynb) to the temporary folder or mount the Colab Notebook and update file paths to the destination folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BcfiucOIJfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "318e45b8-3866-4706-bf58-3de352ee2684"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8638ee88-3205-4586-a79d-c5f34b1500fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8638ee88-3205-4586-a79d-c5f34b1500fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#To upload file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sUhpzLv4IcRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ba825c-b2c1-4408-bd4c-576b734c3c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "   creating: /content/content/output/\n",
            "   creating: /content/content/output/L3-NPP-D/\n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-02-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-11-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-01-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-12-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-11-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-11-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-04-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-10-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-03-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-12-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-03-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-12-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-04-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-10-21.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-02-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-04-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2022-10-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-01-01.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-03-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-01-11.tif  \n",
            "  inflating: /content/content/output/L3-NPP-D/bb.GEZ_L3-NPP-D_NONE_dekad_converted_2023-02-21.tif  \n",
            "   creating: /content/content/output/L3-AETI-D/\n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-02-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-10-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-04-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-03-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-10-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-11-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-12-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-02-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-10-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-11-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-01-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-01-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-01-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-11-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-04-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-03-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-12-11.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2022-12-21.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-02-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-03-01.tif  \n",
            "  inflating: /content/content/output/L3-AETI-D/bb.GEZ_L3-AETI-D_NONE_dekad_converted_2023-04-21.tif  \n",
            "   creating: /content/content/output/L3-T-D/\n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-02-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-04-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-01-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-03-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-03-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-11-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-01-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-12-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-10-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-04-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-01-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-02-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-12-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-02-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-03-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-11-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2023-04-21.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-12-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-10-11.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-11-01.tif  \n",
            "  inflating: /content/content/output/L3-T-D/bb.GEZ_L3-T-D_NONE_dekad_converted_2022-10-21.tif  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/data.zip' -d '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oShoN5_YzN91"
      },
      "source": [
        "## Step 1. Import raster (WaPOR) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP3vPYnbMti9"
      },
      "source": [
        "In this section you will be importing the WaPOR data. First identify the location of the WaPORv3 data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VfzTzdl75lh1"
      },
      "outputs": [],
      "source": [
        "dir_proj = os.path.split(os.getcwd())[0]\n",
        "dir_data = \"/content/content/output/\"\n",
        "input_folderAETI = os.path.join(dir_proj, dir_data, \"L3-AETI-D\")\n",
        "input_fhsAETI = glob.glob(os.path.join(input_folderAETI, '*.tif'))\n",
        "\n",
        "input_folderT = os.path.join(dir_proj, dir_data, \"L3-T-D\")\n",
        "input_fhsT = glob.glob(os.path.join(input_folderT, '*.tif'))\n",
        "\n",
        "input_folderNPP = os.path.join(dir_proj, dir_data, \"L3-NPP-D\")\n",
        "input_fhsNPP = glob.glob(os.path.join(input_folderNPP, '*.tif'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NiGFLfUS6j3"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "\n",
        "**NOTE:** Before continuing with the next steps, make sure that you already have the data needed in the folders below.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2IvCc4j_S6j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e486a09-d7a4-4665-ef5a-e6f55596430f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder of input AETI data: /content/content/output/L3-AETI-D\n",
            "Folder of input T data: /content/content/output/L3-T-D\n",
            "Folder of input NPP data: /content/content/output/L3-NPP-D\n"
          ]
        }
      ],
      "source": [
        "print('Folder of input AETI data: '+input_folderAETI)\n",
        "print('Folder of input T data: '+input_folderT)\n",
        "print('Folder of input NPP data: '+input_folderNPP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7drh74nS6j3"
      },
      "source": [
        "This script defines (and create) the output folder (same folder for all seasonal files)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzcvC9iRUuG6"
      },
      "outputs": [],
      "source": [
        "output_folderAETI = \"/content/output/AETI_season\"\n",
        "output_folderT = \"/content/output/T_season\"\n",
        "output_folderNPP = \"/content/output/NPP_season\"\n",
        "\n",
        "if not os.path.exists(output_folderAETI):\n",
        "    os.makedirs(output_folderAETI)\n",
        "output_folderAETI\n",
        "\n",
        "if not os.path.exists(output_folderT):\n",
        "    os.makedirs(output_folderT)\n",
        "output_folderT\n",
        "\n",
        "if not os.path.exists(output_folderNPP):\n",
        "    os.makedirs(output_folderNPP)\n",
        "output_folderNPP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvbIlMLGzN93"
      },
      "source": [
        "## Step 2. Define function for temporal aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Yj9ksmWt36"
      },
      "source": [
        "This script defines the function `SumSeason` which is used in the next sections. Using functions in such a way improves the readability and replicability of the scripts and avoids errors. For example we need this function to aggregate AETI and NPP data.\n",
        "\n",
        "© 2020 Abebe Chukalla. Licensed under CC BY 4.0 Creative Commons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uHincWTXzN93"
      },
      "outputs": [],
      "source": [
        "# summation of raster between two dates\n",
        "def SumSeason(input_fhs, sowing_date, harvesting_date):\n",
        "\n",
        "    # add rasters that falls within sowing and harvesting date\n",
        "    Sums = 0\n",
        "    for i, in_fh in enumerate(input_fhs):\n",
        "        # open raster file and get start and end date from attributes\n",
        "        ds = rio.open_rasterio(in_fh)\n",
        "        ds = ds.where(ds!=ds.attrs['_FillValue'])\n",
        "        if i == 0:\n",
        "          attrs = ds.attrs\n",
        "        raster_startdate = datetime.datetime.strptime(ds.attrs['start_date'], '%Y-%m-%d' ).date()\n",
        "        raster_enddate   = datetime.datetime.strptime(ds.attrs['end_date'], '%Y-%m-%d' ).date()\n",
        "\n",
        "        # accumulate full or part of the dekadal value\n",
        "        if (raster_startdate >= sowing_date) & (raster_enddate <= harvesting_date):\n",
        "            Sum = ds\n",
        "            Sums += Sum\n",
        "#             print (\"1\",in_fh)\n",
        "\n",
        "        elif (raster_startdate <sowing_date)&(raster_enddate >sowing_date)&(raster_enddate <harvesting_date):\n",
        "            Sum = ds\n",
        "            Sum = Sum*((raster_enddate-sowing_date)/(raster_enddate-raster_startdate))\n",
        "            Sums += Sum\n",
        "#             print (\"2\",in_fh)\n",
        "\n",
        "        elif (raster_startdate >sowing_date)&(raster_startdate <harvesting_date)&(raster_enddate >harvesting_date):\n",
        "            Sum = ds\n",
        "            Sum = Sum*((harvesting_date- raster_startdate)/(raster_enddate-raster_startdate))\n",
        "            Sums += Sum\n",
        "#             print (\"3\",in_fh)\n",
        "\n",
        "        elif (sowing_date>=raster_startdate)&(harvesting_date<=raster_enddate):\n",
        "            Sum = ds\n",
        "            Sum = Sum*((harvesting_date- sowing_date)/(raster_enddate-raster_startdate))\n",
        "            Sums += Sum\n",
        "#             print (\"4\",in_fh)\n",
        "    attrs.update({'start_date':datetime.datetime.strftime(SOS, '%Y-%m-%d'),\n",
        "              'end_date': datetime.datetime.strftime(EOS, '%Y-%m-%d'),\n",
        "              'units' : 'mm/season'})\n",
        "    del attrs['number_of_days']\n",
        "    del attrs['temporal_resolution']\n",
        "    del attrs['units_conversion_factor']\n",
        "\n",
        "    Sums.attrs  = attrs\n",
        "    return Sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRlG-gHLzN95"
      },
      "source": [
        "## Step 3. Calculate seasonal AETI, T and NPP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define seasons\n",
        "\n",
        "Here the start (SOS) and end (EOS) dates for each season are defined."
      ],
      "metadata": {
        "id": "f2oLPCkTHdkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6pkbN3awOAli"
      },
      "outputs": [],
      "source": [
        "season_periods = {\n",
        "    'season1': {'SOS': '2022-10-01', 'EOS': '2023-04-30'}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNit074EZQmp"
      },
      "source": [
        "## i) Calculate seasonal Actual Evapotranspiration and Interception (AETI)\n",
        "\n",
        "In this script the start and end date of each season is read and then the function `SumSeason` is called. Seasonally aggregated data is then saved, and mean and standard deviation (SD) calculated for each season. Final part of the script is plotting all maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8cDVk1XzN95"
      },
      "outputs": [],
      "source": [
        "# Assign inputs to the SumSeason function\n",
        "input_fhs      = input_fhsAETI\n",
        "output_folder  = output_folderAETI\n",
        "\n",
        "\n",
        "for i, season in enumerate(season_periods):\n",
        "    # calculate the seasonal value and save in output_folder\n",
        "    SOS = datetime.datetime.strptime(season_periods[season]['SOS'],'%Y-%m-%d').date()\n",
        "    EOS = datetime.datetime.strptime(season_periods[season]['EOS'],'%Y-%m-%d').date()\n",
        "    seasonal = SumSeason(input_fhs, SOS, EOS)\n",
        "\n",
        "    ## save the array in raster format, name it with the raster_id and sowing and harvesting date\n",
        "    out_fh = os.path.join(output_folder, 'AETI' + '_' + season + '_' + season_periods[season]['SOS']+'_to_'+season_periods[season]['EOS']+ '.tif')\n",
        "    seasonal.rio.to_raster(out_fh)\n",
        "\n",
        "    # calculate the mean, SD\n",
        "    print ('the mean, SD for ', season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], '=', np.nanmean(seasonal).round(1),'&',np.nanstd(seasonal).round(1))\n",
        "\n",
        "    # Plot the raster map\n",
        "    spatial_extent = (seasonal.x.min(), seasonal.x.max(), seasonal.y.min(), seasonal.y.max())\n",
        "    plt.figure(figsize = (12,8))\n",
        "    plt.imshow(seasonal[0], cmap='jet_r', vmin=np.nanmin(seasonal), vmax=np.nanmax(seasonal), extent=spatial_extent)\n",
        "    plt.colorbar(shrink=0.75, label='AETI [mm/season]')\n",
        "    plt.xlabel('Longitude [m]', fontsize=14)  # add axes label\n",
        "    plt.ylabel('Latitude [m]', fontsize=14)\n",
        "    plt.title('AETI [mm/season] ' + season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], fontsize=16)\n",
        "    plt.clim()\n",
        "    plt.show ();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ii) Calculate seasonal Transpiration (T)\n",
        "\n"
      ],
      "metadata": {
        "id": "pO2HMx8Sa_XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign inputs to the SumSeason function\n",
        "input_fhs      = input_fhsT\n",
        "output_folder  = output_folderT\n",
        "\n",
        "\n",
        "for i, season in enumerate(season_periods):\n",
        "    # calculate the seasonal value and save in output_folder\n",
        "    SOS = datetime.datetime.strptime(season_periods[season]['SOS'],'%Y-%m-%d').date()\n",
        "    EOS = datetime.datetime.strptime(season_periods[season]['EOS'],'%Y-%m-%d').date()\n",
        "    seasonal = SumSeason(input_fhs, SOS, EOS)\n",
        "\n",
        "    ## save the array in raster format, name it with the raster_id and sowing and harvesting date\n",
        "    out_fh = os.path.join(output_folder, 'T' + '_' + season + '_' + season_periods[season]['SOS']+'_to_'+season_periods[season]['EOS']+ '.tif')\n",
        "    seasonal.rio.to_raster(out_fh)\n",
        "\n",
        "    # calculate the mean, SD\n",
        "    print ('the mean, SD for ', season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], '=', np.nanmean(seasonal).round(1),'&',np.nanstd(seasonal).round(1))\n",
        "\n",
        "    # Plot the raster map\n",
        "    spatial_extent = (seasonal.x.min(), seasonal.x.max(), seasonal.y.min(), seasonal.y.max())\n",
        "    plt.figure(figsize = (12,8))\n",
        "    plt.imshow(seasonal[0], cmap='jet_r', vmin=np.nanmin(seasonal), vmax=np.nanmax(seasonal), extent=spatial_extent)\n",
        "    plt.colorbar(shrink=0.75, label='T [mm/season]')\n",
        "    plt.xlabel('Longitude [m]', fontsize=14)  # add axes label\n",
        "    plt.ylabel('Latitude [m]', fontsize=14)\n",
        "    plt.title('T [mm/season] ' + season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], fontsize=16)\n",
        "    plt.clim()\n",
        "    plt.show ();"
      ],
      "metadata": {
        "id": "Lkp00dHNbNxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77TTu5_saJwQ"
      },
      "source": [
        "## iiI) Calculate seasonal Net Primary Production (NPP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB2Gbz-DzN96"
      },
      "outputs": [],
      "source": [
        "# Assign inputs to the SumSeason function\n",
        "input_fhs      = input_fhsNPP\n",
        "output_folder  = output_folderNPP\n",
        "\n",
        "\n",
        "for i, season in enumerate(season_periods):\n",
        "    # calculate the seasonal value and save in output_folder\n",
        "    SOS = datetime.datetime.strptime(season_periods[season]['SOS'],'%Y-%m-%d').date()\n",
        "    EOS = datetime.datetime.strptime(season_periods[season]['EOS'],'%Y-%m-%d').date()\n",
        "    seasonal = SumSeason(input_fhs, SOS, EOS)\n",
        "\n",
        "    ## save the array in raster format, name it with the raster_id and sowing and harvesting date\n",
        "    out_fh = os.path.join(output_folder, 'NPP' + '_' + season + '_' + season_periods[season]['SOS']+'_to_'+season_periods[season]['EOS']+ '.tif')\n",
        "    seasonal.rio.to_raster(out_fh)\n",
        "\n",
        "    # calculate the mean, SD\n",
        "    print ('the mean, SD for ', season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], '=', np.nanmean(seasonal).round(1),'&',np.nanstd(seasonal).round(1))\n",
        "\n",
        "    # Plot the raster map\n",
        "    spatial_extent = (seasonal.x.min(), seasonal.x.max(), seasonal.y.min(), seasonal.y.max())\n",
        "    plt.figure(figsize = (12,8))\n",
        "    plt.imshow(seasonal[0], cmap='jet_r', vmin=np.nanmin(seasonal), vmax=np.nanmax(seasonal), extent=spatial_extent)\n",
        "    plt.colorbar(shrink=0.75, label='NPP [gC/m2/season]')\n",
        "    plt.xlabel('Longitude [m]', fontsize=14)  # add axes label\n",
        "    plt.ylabel('Latitude [m]', fontsize=14)\n",
        "    plt.title('NPP [gC/m2/season] ' + season_periods[season]['SOS'] + '/' + season_periods[season]['EOS'], fontsize=16)\n",
        "    plt.clim()\n",
        "    plt.show ();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zip and download seasonal data"
      ],
      "metadata": {
        "id": "FFq_D8yE255i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/WaPORv3_seasonal.zip /content/output/\n",
        "from google.colab import files\n",
        "files.download(r'/content/WaPORv3_seasonal.zip')\n"
      ],
      "metadata": {
        "id": "OO74Is8x28Vy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}